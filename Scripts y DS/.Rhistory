# Cargar el dataset
data <- read.csv("usuarios.csv", sep=";")
# Calcular la frecuencia de las alergias
# strsplit para dividir los nombres separados por coma
# en elementos individuales
ingredientes_separados <- strsplit(data$alergias, ",")
# unlist para crear un vector para poner los nombres separados
ingredientes <- unlist(ingredientes_separados)
tabla_de_frecuencia <- table(ingredientes)
# ordenar de menor a mayor las frecuencias
alergias_ordenadas <- sort(tabla_de_frecuencia, decreasing = TRUE)
alergia_mas_comun <- names(alergias_ordenadas)[1] # alergia ubicada en el #1
# Imprimir el resultado
cat("La alergia mÃ¡s comÃºn es:", alergia_mas_comun)
# graficar
plot(alergias_ordenadas)
# Convertir la variable de respuesta en un factor
data$cantidad_alergias <- as.factor(data$cantidad_alergias)
# Convertir la variable de respuesta en un factor
data$cantidad_alergias <- as.factor(data$cantidad_alergias)
# Convertir la variable de respuesta en un factor
data$cantidad_alergias <- as.factor(data$cantidad_alergias)
# Cargar el dataset
data <- read.csv("usuarios.csv", sep=";")
# Convertir la variable de respuesta en un factor
data$cantidad_alergias <- as.factor(data$cantidad_alergias)
# Cargar el dataset
data <- read.csv("usuarios.csv", sep=";")
# Cargar el dataset
data <- read.csv("usuarios.csv", sep=";")
# Convertir la variable de respuesta en un factor
data$cantidad_alergias <- as.factor(data$cantidad_alergias)
# Cargar el dataset
data <- read.csv("usuarios.csv", sep=";")
# Convertir la variable de respuesta en un factor
data_cantidad_alergias <- as.factor(data$cantidad_alergias)
# Ajustar un modelo de regresión logística
modelo <- glm(cantidad_alergias ~ ., data = data, family = binomial)
# Convertir la variable de respuesta en un factor
data_cantidad_alergias <- as.factor(data$cantidad_alergias)
# Ajustar un modelo de regresión logística
modelo <- glm(cantidad_alergias ~ ., data = data, family = binomial)
# Obtener las predicciones
predicciones <- predict(modelo, type = "response")
# Probando KNN
# Instalar el paquete 'class' si aún no está instalado
install.packages("class")
# Cargar la biblioteca 'class'
library(class)
# Datos de ejemplo
X <- matrix(c(1, 2, 2, 3, 2, 1, 3, 2), ncol = 2, byrow = TRUE)
y <- c(0, 0, 1, 1)
# Dividir los datos en conjuntos de entrenamiento y prueba
set.seed(42)
indices <- sample(1:nrow(X), nrow(X)*0.8)
# 80% de los datos para entrenamiento
X_train <- X[indices, ]
y_train <- y[indices]
X_test <- X[-indices, ]
y_test <- y[-indices]
# Crear el modelo KNN con k = 3
k <- 3
knn_model <- knn(train = X_train, test = X_test, cl = y_train, k = k)
# Calcular la precisión del modelo
accuracy <- sum(knn_model == y_test) / length(y_test)
cat("Precisión del modelo:", accuracy)
View(X)
View(X)
# Datos de ejemplo
X <- matrix(data$numero_alergias, ncol = 2, byrow = TRUE)
y <- c(0, 0, 1, 1)
# Dividir los datos en conjuntos de entrenamiento y prueba
set.seed(42)
indices <- sample(1:nrow(X), nrow(X)*0.8)
# 80% de los datos para entrenamiento
X_train <- X[indices, ]
y_train <- y[indices]
X_test <- X[-indices, ]
y_test <- y[-indices]
# Crear el modelo KNN con k = 3
k <- 3
knn_model <- knn(train = X_train, test = X_test, cl = y_train, k = k)
# Datos de ejemplo
X <- matrix(data$numero_alergias, byrow = TRUE)
y <- c(0, 0, 1, 1)
# Dividir los datos en conjuntos de entrenamiento y prueba
set.seed(42)
indices <- sample(1:nrow(X), nrow(X)*0.8)
# 80% de los datos para entrenamiento
X_train <- X[indices, ]
y_train <- y[indices]
X_test <- X[-indices, ]
y_test <- y[-indices]
# Crear el modelo KNN con k = 3
k <- 3
knn_model <- knn(train = X_train, test = X_test, cl = y_train, k = k)
# Calcular la precisión del modelo
accuracy <- sum(knn_model == y_test) / length(y_test)
ncol = 2
ncol = 2
ncol = 2
# Probando KNN
# Instalar el paquete 'class' si aún no está instalado
install.packages("class")
# Cargar la biblioteca 'class'
library(class)
# Datos de ejemplo
X <- matrix(data$numero_alergias, ncol = 2, byrow = TRUE)
y <- c(0, 0, 1, 1)
# Dividir los datos en conjuntos de entrenamiento y prueba
set.seed(42)
indices <- sample(1:nrow(X), nrow(X)*0.8)
# 80% de los datos para entrenamiento
X_train <- X[indices, ]
y_train <- y[indices]
X_test <- X[-indices, ]
y_test <- y[-indices]
# Crear el modelo KNN con k = 3
k <- 3
knn_model <- knn(train = X_train, test = X_test, cl = y_train, k = k)
# Probando KNN
# Instalar el paquete 'class' si aún no está instalado
#install.packages("class")
# Cargar la biblioteca 'class'
library(class)
# Datos de ejemplo
X <- matrix(data$numero_alergias, ncol = 2, byrow = TRUE)
y <- c(0, 0, 1, 1)
# Dividir los datos en conjuntos de entrenamiento y prueba
set.seed(42)
indices <- sample(1:nrow(X), nrow(X)*0.8)
indices
indices <- sample(1:nrow(X), nrow(X)*0.8)
# 80% de los datos para entrenamiento
X_train <- X[indices, ]
View(X_train)
View(X_train)
View(X_train)
y_train <- y[indices]
X_test <- X[-indices, ]
y_test <- y[-indices]
# Crear el modelo KNN con k = 3
k <- 3
knn_model <- knn(train = X_train, test = X_test, cl = y_train, k = k)
knn_model <- knn(train = X_train, test = X_test, cl = y_train, k = k)
View(X_train)
y_test <- y[-indices]
# Crear el modelo KNN con k = 3
k <- 3
knn_model <- knn(train = X_train, test = X_test, cl = y_train, k = k)
# Probando KNN
# Instalar el paquete 'class' si aún no está instalado
#install.packages("class")
# Cargar la biblioteca 'class'
library(class)
# Datos de ejemplo
X <- matrix(data$numero_alergias, ncol = 2, byrow = TRUE)
y <- c(0, 0, 1, 1)
# Dividir los datos en conjuntos de entrenamiento y prueba
set.seed(42)
indices <- sample(1:nrow(X), nrow(X)*0.8)
# 80% de los datos para entrenamiento
X_train <- X[indices, ]
y_train <- y[indices]
X_test <- X[-indices, ]
y_test <- y[-indices]
# Crear el modelo KNN con k = 3
k <- 3
knn_model <- knn(train = X_train, test = X_test, cl = y_train, k = k)
missing_values <- sum(is.na(data))
missing_values
View(data)
data <- na.omit(data)
# 80% de los datos para entrenamiento
X_train <- X[indices, ]
y_train <- y[indices]
X_test <- X[-indices, ]
y_test <- y[-indices]
# Crear el modelo KNN con k = 3
k <- 3
knn_model <- knn(train = X_train, test = X_test, cl = y_train, k = k)
# Calcular la precisión del modelo
accuracy <- sum(knn_model == y_test) / length(y_test)
cat("Precisión del modelo:", accuracy)
View(data)
View(data)
data <- na.aggregate(data, FUN = mean)
# Instalar el paquete 'class' si aún no está instalado
# install.packages("class")
# Cargar la biblioteca 'class'
library(class)
# Datos de ejemplo
X <- matrix(c(1, 2, 2, 3, 2, 1, 3, 2), ncol = 2, byrow = TRUE)
y <- c(0, 0, 1, 1)
# Dividir los datos en conjuntos de entrenamiento y prueba
set.seed(42)
indices <- sample(1:nrow(X), nrow(X)*0.8)
# 80% de los datos para entrenamiento
X_train <- X[indices, ]
y_train <- y[indices]
X_test <- X[-indices, ]
y_test <- y[-indices]
# Crear el modelo KNN con k = 3
k <- 3
knn_model <- knn(train = X_train, test = X_test, cl = y_train, k = k)
# Calcular la precisión del modelo
accuracy <- sum(knn_model == y_test) / length(y_test)
cat("Precisión del modelo:", accuracy)
Ejemplo 2
# Instalar el paquete 'class' si aún no está instalado
# install.packages("class")
# Cargar la biblioteca 'class'
library(class)
# Datos de ejemplo
X <- matrix(c(1, 2, 2, 3, 2, 1, 3, 2), ncol = 2, byrow = TRUE)
y <- c(0, 0, 1, 1)
# Dividir los datos en conjuntos de entrenamiento y prueba
set.seed(42)
indices <- sample(1:nrow(X), nrow(X)*0.8)
# 80% de los datos para entrenamiento
X_train <- X[indices, ]
y_train <- y[indices]
X_test <- X[-indices, ]
y_test <- y[-indices]
# Crear el modelo KNN con k = 3
k <- 3
knn_model <- knn(train = X_train, test = X_test, cl = y_train, k = k)
# Calcular la precisión del modelo
accuracy <- sum(knn_model == y_test) / length(y_test)
cat("Precisión del modelo:", accuracy)
# Ejemplo 2
# Cargar bibliotecas
library(class)
library(datasets)
# Cargar el conjunto de datos Iris
data(iris)
# Dividir los datos en conjuntos de entrenamiento y prueba
set.seed(42)
indices <- sample(1:nrow(iris), nrow(iris)*0.8) # 80% de los datos para
entrenamiento
# Instalar el paquete 'class' si aún no está instalado
# install.packages("class")
# Cargar la biblioteca 'class'
library(class)
# Datos de ejemplo
X <- matrix(c(1, 2, 2, 3, 2, 1, 3, 2), ncol = 2, byrow = TRUE)
y <- c(0, 0, 1, 1)
# Dividir los datos en conjuntos de entrenamiento y prueba
set.seed(42)
indices <- sample(1:nrow(X), nrow(X)*0.8)
# 80% de los datos para entrenamiento
X_train <- X[indices, ]
y_train <- y[indices]
X_test <- X[-indices, ]
y_test <- y[-indices]
# Crear el modelo KNN con k = 3
k <- 3
knn_model <- knn(train = X_train, test = X_test, cl = y_train, k = k)
# Calcular la precisión del modelo
accuracy <- sum(knn_model == y_test) / length(y_test)
cat("Precisión del modelo:", accuracy)
# Instalar el paquete 'class' si aún no está instalado
# install.packages("class")
# Cargar la biblioteca 'class'
library(class)
# Datos de ejemplo
X <- matrix(c(1, 2, 2, 3, 2, 1, 3, 2), ncol = 2, byrow = TRUE)
y <- c(0, 0, 1, 1)
# Dividir los datos en conjuntos de entrenamiento y prueba
set.seed(42)
indices <- sample(1:nrow(X), nrow(X)*0.8)
# 80% de los datos para entrenamiento
X_train <- X[indices, ]
y_train <- y[indices]
X_test <- X[-indices, ]
y_test <- y[-indices]
# Crear el modelo KNN con k = 3
k <- 1
knn_model <- knn(train = X_train, test = X_test, cl = y_train, k = k)
# Calcular la precisión del modelo
accuracy <- sum(knn_model == y_test) / length(y_test)
cat("Precisión del modelo:", accuracy)
# Cargar paquetes necesarios
library(class)
library(ggplot2)
install.packages("ggplot2")
# Cargar paquetes necesarios
library(class)
library(ggplot2)
# Generar datos de ejemplo
set.seed(123)
n <- 100 # Número de puntos de datos
k <- 5 # Número de vecinos cercanos
x1 <- rnorm(n, mean = 0, sd = 1)
x2 <- rnorm(n, mean = 0, sd = 1)
response <- factor(ifelse(x1 + x2 > 0, "Clase A", "Clase B"))
# Crear el dataframe de datos
data <- data.frame(x1, x2, response)
# Dividir los datos en conjunto de entrenamiento y conjunto de prueba
train_indices <- sample(1:n, size = 0.7 * n, replace = FALSE)
# Dividir los datos en conjunto de entrenamiento y conjunto de prueba
train_indices <- sample(1:n, size = 0.7 * n, replace = FALSE)
train_data <- data[train_indices, ]
test_data <- data[-train_indices, ]
# Entrenar el modelo k-NN
knn_model <- knn(train = train_data[, 1:2], test = test_data[, 1:2], cl =
train_data$response, k = k)
# Calcular la precisión del modelo
accuracy <- sum(knn_model == test_data$response) /
length(test_data$response)
cat("Precisión del modelo:", accuracy, "\n")
# Crear una visualización de los resultados
ggplot(data, aes(x = x1, y = x2, color = response)) +
geom_point(size = 0.5) +
geom_point(data = test_data, aes(x = x1, y = x2), color = "black", size = 1,
alpha = 0.5) +
geom_point(data = test_data, aes(x = x1, y = x2, color = knn_model), size
= 3, shape = 4) +
labs(x = "Variable X1", y = "Variable X2", color = "Clase") +
scale_color_manual(values = c("Clase A" = "yellow", "Clase B" = "orange"))
+
theme_minimal()
# Cargar paquetes necesarios
library(class)
library(ggplot2)
# Generar datos de ejemplo
set.seed(123)
n <- 100 # Número de puntos de datos
k <- 5 # Número de vecinos cercanos
x1 <- rnorm(n, mean = 0, sd = 1)
x2 <- rnorm(n, mean = 0, sd = 1)
response <- factor(ifelse(x1 + x2 > 0, "Clase A", "Clase B"))
# Crear el dataframe de datos
data <- data.frame(x1, x2, response)
# Dividir los datos en conjunto de entrenamiento y conjunto de prueba
train_indices <- sample(1:n, size = 0.7 * n, replace = FALSE)
train_data <- data[train_indices, ]
test_data <- data[-train_indices, ]
# Entrenar el modelo k-NN
knn_model <- knn(train = train_data[, 1:2], test = test_data[, 1:2], cl =
train_data$response, k = k)
# Calcular la precisión del modelo
accuracy <- sum(knn_model == test_data$response) /
length(test_data$response)
cat("Precisión del modelo:", accuracy, "\n")
# Crear una visualización de los resultados
ggplot(data, aes(x = x1, y = x2, color = response)) +
geom_point(size = 0.5) +
geom_point(data = test_data, aes(x = x1, y = x2), color = "black", size = 1,
alpha = 0.5) +
geom_point(data = test_data, aes(x = x1, y = x2, color = knn_model), size
= 3, shape = 4) +
labs(x = "Variable X1", y = "Variable X2", color = "Clase") +
scale_color_manual(values = c("Clase A" = "yellow", "Clase B" = "orange"))+
theme_minimal()
# Cargar paquetes necesarios
library(class)
library(ggplot2)
# Generar datos de ejemplo
set.seed(123)
n <- 100 # Número de puntos de datos
k <- 5 # Número de vecinos cercanos
x1 <- rnorm(n, mean = 0, sd = 1)
x2 <- rnorm(n, mean = 0, sd = 1)
response <- factor(ifelse(x1 + x2 > 0, "Clase A", "Clase B"))
# Crear el dataframe de datos
data <- data.frame(x1, x2, response)
# Dividir los datos en conjunto de entrenamiento y conjunto de prueba
train_indices <- sample(1:n, size = 0.7 * n, replace = FALSE)
train_data <- data[train_indices, ]
test_data <- data[-train_indices, ]
# Entrenar el modelo k-NN
knn_model <- knn(train = train_data[, 1:2], test = test_data[, 1:2], cl =
train_data$response, k = k)
# Calcular la precisión del modelo
accuracy <- sum(knn_model == test_data$response) /
length(test_data$response)
cat("Precisión del modelo:", accuracy, "\n")
# Crear una visualización de los resultados
ggplot(data, aes(x = x1, y = x2, color = response)) +
geom_point(size = 0.5) +
geom_point(data = test_data, aes(x = x1, y = x2), color = "black", size = 1,
alpha = 0.5) +
geom_point(data = test_data, aes(x = x1, y = x2, color = knn_model), size
= 3, shape = 4) +
labs(x = "Variable X1", y = "Variable X2", color = "Clase") +
scale_color_manual(values = c("Clase A" = "yellow", "Clase B" = "orange"))+
theme_minimal()
# Crear una visualización de los resultados
ggplot(data, aes(x = x1, y = x2, color = response)) +
geom_point(size = 0.5) +
geom_point(data = test_data, aes(x = x1, y = x2), color = "black", size = 1,
alpha = 0.5) +
geom_point(data = test_data, aes(x = x1, y = x2, color = knn_model), size
= 3, shape = 4) +
labs(x = "Variable X1", y = "Variable X2", color = "Clase") +
scale_color_manual(values = c("Clase A" = "blue", "Clase B" = "red"))+
theme_minimal()
# Crear una visualización de los resultados
ggplot(data, aes(x = x1, y = x2, color = response)) +
geom_point(size = 0.5) +
geom_point(data = test_data, aes(x = x1, y = x2), color = "black", size = 1,
alpha = 0.5) +
geom_point(data = test_data, aes(x = x1, y = x2, color = knn_model), size
= 3, shape = 4) +
labs(x = "Variable X1", y = "Variable X2", color = "Clase") +
scale_color_manual(values = c("Clase A" = "blue", "Clase B" = "red"))+	theme_minimal()
# Cargar el dataset
data <- read.csv("usuarios.csv", sep=";")
data_alergias <- data[, c("alergias")]
# Crear una matriz binaria (one-hot encoding) para las alergias
alergias <- strsplit(data_alergias$alergias, ",")
data_alergias <- data[, c("alergias")]
# Crear una matriz binaria (one-hot encoding) para las alergias
alergias <- strsplit(data_alergias$alergias, ",")
source("~/.active-rstudio-document", encoding = 'UTF-8', echo=TRUE)
# Crear una matriz binaria (one-hot encoding) para las alergias
alergias <- strsplit(data_alergias$alergias, ",")
data_alergias <- data[, c("alergias")]
# Crear una matriz binaria (one-hot encoding) para las alergias
alergias <- strsplit(data_alergias$alergias, ",")
